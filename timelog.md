# Timelog

* "A Picture is worth a Thousand Words": Automatic Illustration of Text via Multimodal Interaction
* Dominykas Meistas
* 2404288
* Debasis Ganguly

## Week 1

### 20 Sep 2021

* *4 hours* read project guidance notes
* *4 hours* read projects descriptions during bidding process

### 21 Sep 2021

* *6 hours* read projects descriptions during bidding process

### 22 Sep 2021

* *6 hours* read projects descriptions during bidding process

## Week 3

### 4 Oct 2021

* *2 hours* read and analyse the paper about multimodal information retrieval - https://www.researchgate.net/profile/Faraz_Hasan/publication/255686190_Multimodal_Information_Retrieval_Challenges_and_Future_Trends/links/02e7e5202a8f8be344000000/Multimodal-Information-Retrieval-Challenges-and-Future-Trends.pdf

### 5 Oct 2021

* *2 hours* read and analyse paper about multimodal interaction - https://www.sciencedirect.com/science/article/pii/S0167865513002584
* *2 hours* research the tools that will be necessary throughout project

### 6 Oct 2021

* *1 hour* take notes of previously read papers about multimodal information retrieval and multimodal interaction
* *2 hours* skim through some papers about multimodal interaction
* *1 hour* prepare for meeting with supervisor

### 7 Oct 2021

* *0.5 hour* attend the meeting with the supervisor 

### 10 Oct 2021

* *2 hours* analyse the ideas proposed by the supervisor in the meeting and write meeting minutes

## Week 4

### 11 Oct 2021

* *0.5 hour* setup a reference manager
* *2 hours* analyse the CLIP project and zero-shot learning

### 12 Oct 2021 

* *0.5 hour* learn more about zero-shot learning - https://www.youtube.com/watch?v=0iKsimVvfjE
* *1 hour* read about capturing semantic meaning using deep learning (word embedding) and further investigate zero-shot learning

### 13 Oct 2021 

* *2.5 hours* further analyse the paper about zero-shot learning, making extensive notes and focusing on model description and experiments sections - https://arxiv.org/pdf/1312.5650.pdf 
* *1 hour* analyse the paper about knowledge-augmented visual question answering - https://arxiv.org/pdf/2103.05568.pdf 
* *30 mins* make slides and prepare for the meeting 

### 14 Oct 2021

* *1 hour* prepare for the meeting
* *30 mins* attend the meeting with the supervisor

### 15 Oct 2021 

* *1 hour* analyse the ideas from the meeting and writing meeting minutes 
* *1 hour* start analysing the DeViSE paper: https://papers.nips.cc/paper/2013/file/7cce53cf90577442771720a370c3c723-Paper.pdf 

### 16 Oct 2021 

* *1 hour* finish analysing the DeViSE paper: https://papers.nips.cc/paper/2013/file/7cce53cf90577442771720a370c3c723-Paper.pdf 
* *1 hour* start analysing the paper that improves the skip-gram model from the DeViSE paper: https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf 

### 17 Oct 2021 

* *1 hour* finish analysing the paper that improves the skip-gram model from the DeViSE paper: https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf 
* *1 hour* looking for new papers and skimming through a paper about triplet network: https://www.sciencedirect.com/science/article/pii/S0031320321000765 

## Week 5

### 18 Oct 2021 

* *2 hours* further research triplet networks, reading a paper about dual triplet network for image zero-shot learning, trying to understand different topics such as hard triplet mining strategy, hardest positive/negative sample pair, etc.

### 19 Oct 2021 

* *2 hours* further analyse papers concerning triplet networks: 

### 20 Oct 2021 

* *3.5 hours* re-visit the papers analysed this week, summarize different ideas proposed, make slides for the meeting with the supervisor 

### 21 Oct 2021 

* *1 hour* attend the meeting with the supervisor 
* *1.5 hours* analyse the ideas proposed in the meeting, write meeting minutes, start thinking about the datasets and evaluations that we could use 

### 24 Oct 2021 

* *1.5 hours* setup dissertation template on LaTeX, start reading about different datasets we could use (WIT, MS COCO, ImageNet, OID, COCO-Text V2.0) 

## Week 6

### 25 Oct 2021 

* *2 hours* continue reading about different datasets, making a list of pros and cons, thinking of different evaluation ways 

### 26 Oct 2021 

* *2 hours* analyse datasets in more depth (WIT, MS COCO, OID) 

### 27 Oct 2021 

* *1 hour* further analyse datasets in more depth (OID, ImageNet, COCO-Text V2.0) 

## Week 7

### 1 Nov 2021 

* *1 hour* update the final dissertation template, start documenting choices made about the datasets and evaluation methods 

### 2 Nov 2021 

* *2 hours* continue documenting about dataset choices and evaluation methods in the dissertation template, trying to decide which datasets are superior to others 

### 3 Nov 2021 

* *1.5 hours* finish writing dissertation section about different datasets and their evaluation, finalise some points about the different datasets, make slides for the meeting with the supervisor 

### 4 Nov 2021 

* *30 mins* attend the meeting with the supervisor 
* *2 hours* write meeting minutes, listen to meeting recording, analyse the ideas proposed in the meeting, think about the final model 

### 6 Nov 2021 

* *1 hour* analyse the “Multi-Modal Supplementary-Complementary Summarization using Multi-Objective Optimization” paper - https://dl.acm.org/doi/pdf/10.1145/3404835.3462877 

### 7 Nov 2021 

* *2.5 hours* download the WIT dataset, work on figuring out the best approach to this problem, start writing an overview of my proposed approach 

## Week 8

### 8 Nov 2021 

* *2 hours* continue working on my proposed approach, start drawing the workflow diagram 

### 9 Nov 2021 

* *0.5 hour* finalise the workflow diagram 

### 10 Nov 2021 

* *0.5 hour* prepare for the meeting with the supervisor 

### 11 Nov 2021 

* *0.5 hour* attend a meeting with the supervisor 
* *1.5 hours* analyse the ideas from the meeting, make meeting minutes 

## Week 9

### 17 Nov 2021 

* *3 hours* work on making an evaluation set 
* *2 hours* read about Lucene, try to build an index 

### 18 Nov 2021 

* *30 mins* attend the meeting with the supervisor 
* *30 mins* analyse the ideas from the meeting, make meeting minutes 

## Week 10

### 25 Nov 2021 

* *2 hours* analyse Luc4IR code 

### 27 Nov 2021 

* *2 hours* start building text index using Luc4IR 

## Week 11

### 30 Nov 2021 

* *4 hours* continue trying to get the Luc4IR to work, in order to build the text index 

### 1 Dec 2021 

* *3 hours* try to work out why the script to build the text index is not working, running it on different systems (Windows, WSL - Ubuntu, Manjaro) 
* *5 hours* write a python program to transform the data files from WIT dataset to the format required by the Luc4IR to build the text index 

### 2 Dec 2021 

* *2 hours* write a python program to get the most common words from the text section in the evaluation data set 

### 3 Dec 2021 

* *1.5 hours* upgrade the program that gets the most common words from the text section, write meaningful comments 
* *0.5 hour* attend the meeting with the supervisor 

## Week 13

### 13 Dec 2021 

* *3 hours* watch the individual project lecture recording, which talks about evaluating the project and writing the dissertation 
* *2 hours* set up the environment on a different computer, start analysing Lucene API 

### 14 Dec 2021 

* *7 hours* rewatch last meeting’s recording, make notes, create a Lucene index, work on a program to retrieve relevant documents given a query 

### 15 Dec 2021 

* *3 hours* finish building a small program to retrieve n most relevant documents given a query 
* *5 hours* work on building a simple pipeline (implement functions to read the text sections from a file, turn them into a list of frequency HashMaps, start implementing a function to score the query terms and by calculating document frequency (df) and inverse document frequency (idf) 

### 16 Dec 2021 

* *4 hours* finish implementing a function to score the query terms, pass those terms into the index, retrieve relevant documents 
* *2 hours* write the status report 

### 17 Dec 2021 

* *1 hour* proofread and fix the status report 

### 18 Dec 2021 

* *3 hours* improve the code and write comments 
* *0.5 hour* write last meeting’s minutes 

## Week 1

### 13 Jan 2022

* *1 hour* revisit the project, prepare for the meeting with the supervisor 
* *1 hour* attend the meeting with the supervisor 

## Week 2

### 18 Jan 2022

* *2 hours* rewatch the meeting recording, write meeting minutes, make a work plan 

### 20 Jan 2022

* *3 hours* read about different standard information retrieval metrics, make a presentation 

### 21 Jan 2022

* *1 hour* attend the meeting with the supervisor 

## Week 3

### 24 Jan 2022

* *3 hours* work on extending the evaluation dataset by adding more relevant images 

### 25 Jan 2022

* *3 hours* write a program that collects all the images from the Wikipedia page and its hyperlinks so that it’s easier to refine the relevant images dataset 

### 26 Jan 2022

* *1 hour* watch the meeting recording and make meeting minutes 

### 27 Jan 2022

* *6 hours* try to get Luke to work, debug the index, try to add URL field into the index 

### 28 Jan 2022

* *0.5 hour* attend the meeting with my supervisor 

## Week 4

### 1 Feb 2022

* *0.5 hour* watch the meeting recording, write meeting minutes, plan the work 
* *1.5 hours* modify the program that generates input files to the indexer, so that it only has 2 fields (document id and text section) instead of 4 as it had before 

### 2 Feb 2022

* *1 hour* fix the bug where the program generating input files to the indexer would take wrong fields from the Wikipedia dataset (instead of text section content it would take other fields, such as section title) 

### 3 Feb 2022

* *1.5 hour* try to fix the program that provides an input file to the indexer because it gives text section names instead of their content to the indexer 
* *2.5 hours* try to compare retrieved images with ground truth images so that we can compute standard information retrieval metrics (such as P@5) 
* *2 hours* fix the program that provides an input file to the indexer, create a better version of index using the updated input file 
* *3 hours* create a new evaluation dataset that contains many relevant images, create a file that maps text sections and their ids, create a file that maps image URLs and document ids, start writing a new retriever program that retrieves relevant document ids from the index given text section ids, modify the program that generates input files for the indexer so that it generates only one big file containing all the data instead of ten smaller ones

### 4 Feb 2022

* *0.5 hour* attend the meeting with the supervisor 
* *0.5 hour* watch the meeting recording and write meeting minutes 
* *1 hour* work on fixing the indexer to take image captions instead of text section content 

### 5 Feb 2022

* *2 hours* fix the indexer to contain 3 fields (document id, image URL, image caption), start writing a program that retrieves document ids based on image URLs received 

## Week 5

### 9 Feb 2022

* *1 hour* try to retrieve document ids based on image URLs 

### 10 Feb 2022

* *2 hours* finalise a program that takes evaluation data set as input (which contains 3 fields: query id, text section content, and a comma separated list of relevant image URLs), and returns a similar data set, just replaces relevant image URLs by a comma separated list of relevant image ids (equivalent to document ids) 
* *2 hours* modify the retriever program so that it works with ids (now it takes a text section as input and returns a list of retrieved document ids, which we can later compare with our ground truth document ids) 
* *1 hour* modify the retriever program to apply EnglishAnalyzer to the query text sections 
* *4 hours* modify the retriever to calculate evaluation metrics (P@K, Recall, MRR, AP) 

### 11 Feb 2022

* *1 hour* attend the meeting with the supervisor 

## Week 6

### 17 Feb 2022

* *2 hours* watch the previous meeting recording, write meeting minutes, make a testing program to test our index 
* *2 hours* apply the same analyser in retriever as the one in the indexer (which removes custom stop words instead of default ones), try the model with different numbers of retrieved documents, fix the code of functions calculating precision, recall, MRR and AP 

### 18 Feb 2022

* *1 hour* attend the meeting with the supervisor 

## Week 7

### 22 Feb 2022

* *1 hour* watch last meeting’s recording, write meeting minutes 

### 23 Feb 2022

* *3 hours* build an evaluator program that varies our parameters (in this case the number of top query words and the k and b parameters of the BM25 similarity function) and gathers results 
* *3 hours* build a program that analyses the results and draws graphs 

### 24 Feb 2022

* *2 hours* improve the program to get graphs for both BM25 parameters and number of top query words 
* *3.5 hours* write dissertation (sections about formatting the original WIT Dataset, building the index, building the evaluation dataset, querying the index, different retrieval models) 
* *2 hours* write dissertation (sections about evaluating the model and modifying the parameters) 

### 25 Feb 2022

* *0.5 hour* attend the meeting with the supervisor 

## Week 8

### 2 Mar 2022

* *1 hour* watch the meeting recording and write meeting notes 

### 3 Mar 2022

* *7 hours* refactor the retriever to use public classes instead of static ones, try to apply relevance feedback 

### 4 Mar 2022

* *2.5 hour* continue attempting to apply relevance feedback to the query 
* *0.5 hour* attend the meeting with the supervisor 

## Week 9

### 9 Mar 2022

* *1 hour* watch the recording of the last meeting, write meeting minutes, think about the goals of this week 
* *2 hours* find and fix the bug causing performance metrics’ values to be formatted incorrectly when printed to file (the function was checking whether to add a coma after each number or not, by checking if the number is the same as the last number in the list, however, numbers can repeat themselves, which means multiple commas were missing), find and fix the bug where a lot more performance metrics’ values were generated than it was supposed to (the retriever object was created only once, which caused the values list to be incremented for each iteration, which made it grow by the number of queries for each iteration)
* *2 hours* create another Retriever class that extends TrecDocRetriever with the only difference of how it obtains the Query objects 

### 10 Mar 2022

* *1 hour* try to apply relevance feedback to the queries (in the new Retriever class that extends TrecDocRetriever) 

### 11 Mar 2022

* *1 hour* finish applying relevance feedback to the queries and make retriever work with different query window sizes (instead of taking a single query word we also take a few words around it as a context) 
* *2 hours* implement a program that takes a number of levels k, and a name of a Wikipedia page, and returns all the images from the original page and its sub-pages that are linked from the original page (depending on the number of levels) 
* *0.5 hour* try to understand why evaluator is not working on the new Retriever class 
* *1 hour* attend the meeting with the supervisor 

## Week 10

### 14 Mar 2022

* *1.5 hour* watch the recording of the last meeting with the supervisor and write meeting minutes 

### 17 Mar 2022

* *4 hours* correct dissertation sections based on given comments 

### 18 Mar 2022

* *0.5 hour* correct dissertation sections based on given comments 
* *1 hour* create a program to gather Wikipedia images 
* *0.5 hour* format extended evaluation files 
* *0.5 hour* create .adhoc file based on res.txt file 
* *1 hour* change the graphs to represent the percentage of query words instead of a fixed number 
* *0.5 hour* attempt to work out why the result metrics are so high 
* *1 hour* attend the meeting with the supervisor 
* *0.5 hour* fix the .qrel file to contain the ground truth instead of result entries 
* *1.5 hour* work on dissertation 

### 20 Mar 2022

* *1 hour* work on dissertation introduction 

## Week 11

### 21 Mar 2022

* *4 hours* work on dissertation introduction 

### 22 Mar 2022

* *5.5 hours* work on dissertation introduction 

### 23 Mar 2022

* *3.5 hours* work on dissertation 

### 24 Mar 2022

* *1 hour* work on dissertation 

### 25 Mar 2022

* *5 hours* work on dissertation 

### 26 Mar 2022

* *4 hours* work on dissertation 

### 27 Mar 2022

* *5 hours* work on dissertation 

## Week 12

### 28 Mar 2022

* *7 hours* work on dissertation 

### 29 Mar 2022

* *8 hours* work on dissertation 

### 30 Mar 2022

* *7 hours* work on dissertation 

### 31 Mar 2022

* *12 hours* work on dissertation 

### 1 Apr 2022

* *12 hours* work on dissertation 